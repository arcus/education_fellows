<!--
author:   Joy Payton, Arcus Education, Children's Hospital of Philadelphia
email:    paytonk@chop.edu
version:  0.0.1
language: en
narrator: US English Female
comment:  Reproducibility is essential to scientific efforts.  Generalizability and data reuse are also important for the application and expansion of scientific inquiry. Technology can help achieve these goals.
-->

# Reproducibility, Generalizability, and Reuse

<div style="background-color:#e0ffe0;
padding: 1em;
border: 1px solid grey;">

## Overview

This module provides learners with an approachable introduction to research reproducibility, generalizability, and reuse, and how technical approaches can help.

**Estimated time to completion**: 1 hour

**Pre-requisites**: It is helpful if learners have conducted research, are familiar with peer-reviewed literature, and have experience using data and methods developed by other people.    

**Format**: This module uses text and video and is intended to accompany an in-person or otherwise synchronous presentation.  Materials contained here will allow for review after a live session.

**Learning Objectives**:  After completion of this module, learners will be able to:

* Explain the importance of reproducible methods
* Give an example of a reproducible method in data acquisition and analysis
* Give an example of a reproducible method in data management and metadata

</div>

### Contents

* [Instructor Introduction](#Instructor-Introduction)
* [Reproducibility Crisis](#Reproducibility-Crisis)

### Instructor Introduction

Your live session is facilitated by [Joy Payton](https://linkedin.com/in/joypayton), who leads [data education efforts](https://education.arcus.chop.edu) within the [Arcus program](https://arcus.chop.edu) within the [Research Institute](https://www.research.chop.edu) of the [Children's Hospital of Philadelphia](https://www.chop.edu).

## Concepts

### Reproducibility

The **"reproducibility crisis"** refers to the problem in peer-reviewed research in which studies *cannot* be reproduced or replicated because of insufficient information, or in which studies *fail* to be reproduced or replicated because of preventable problems in the initial research.  This is problematic because it means wasted time and money, reduced public trust in science, unverifiable claims, and lost chances for scientific consensus.

Examples of reproducibility problems exist at small and large scale:

* Experiencing dread at trying to reproduce your own findings a few months after doing it the first time
* Being stymied by a collaborator's cryptic notes that don't explain how to do a particular analysis step
* Being unable to perform required computation because of reliance on expensive, deprecated, or proprietary software or hardware
* Results that don't replicate due to poor statistical practices, such as "p-hacking", "HARKing", or multiple tests without correction

### Generalizability

Research is **generalizable** if findings can be applied to a broad population.  

Historically, biomedical and social science research projects have struggled with generalizability due to unrepresentative data.  For example, the acronym **"WEIRD"** refers to the tendency of psychological studies to rely on subjects (often undergraduate students) who are disproportionately from **W**estern, **E**ducated, **I**ndustrialized, **R**ich, and **D**eveloped cultures -- cultures which, compared with the global population as a whole, are indeed weird.  Until recently, many biomedical studies were conducted on disproportionately male populations and ignored disease presentation or pharmacodynamics in women and girls (or even female lab animals).  In wearable sensor and computer vision development, overwhelmingly white engineers using skewed samples have failed to realize that the optical sensors and computer vision algorithms they created perform less well on dark skin.

The challenge of generalizability is closely linked to reproducibility.  For example, a study that demonstrates the effectiveness of exercise to improve functioning in depressed suburban teenagers may not generalize to city-dwelling adults.  In order to gain broader generalizability, this promising experiment on a limited population should be reproduced in a broader or different population.  If the original study is difficult to reproduce, however, such broader application may prove impossible.

Technological solutions cannot correct recruitment bias or white overrepresentation in research personnel.  Careful use of technology can, however, add to research transparency and reproducibility and promote honest disclosure of challenges to generalizability.

### Reuse

In addition to reproducibility, another important element of research is the ability to reuse assets such as data and methods to related research that may not be a direct replication.  Researchers may hypothesize that a computer vision approach used to analyze moles might be useful as well in other areas of medicine that need edge detection, such as tumor classification.  Longitudinal data that provides rich phenotyping of a cohort of patients with hypermobility syndromes may be useful not just to the original orthopedic researcher community but also to cardiologists interested in comorbid vascular and ANS conditions.  Data reuse allows researchers to collaborate in ways that advance cross-domain knowledge and professional interaction, as well as honoring the time and energy of human subjects whose data can be leveraged to get as much scientific value as possible.

The reuse of data and other research assets has numerous challenges.  You may have experienced problems in this area such as:

* Encountering resistance to sharing data, methods, scripts, or other artifacts
* Data that is not well described or labeled, or is stored in a "supplemental materials" page without context
* Overly strict informed consent documents that prevent researchers from reusing their own data or sharing it with colleagues

### A Data Management and Sharing Snafu

This is an approachable and humorous introduction to the practical impact of poor research practices leading to downstream impact.  As you listen, try to identify problematic research practices which could have been prevented by more careful use of technology.  Which of these mistakes have you encountered personally?  Which have you committed?

<iframe width="560" height="315" src="https://www.youtube.com/embed/N2zK3sAtr-4?cc_load_policy=1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## 
